---
layout: post
title: Caffe实践-1
description: caffe的安装，运行书写体识别例子
keywords: caffe
categories : [deep learning]
tags : [caffe]
---
S
原文： [Caffe实践-1](http://blog.csdn.net/u010458863/article/details/58200772)

作者： [李敏]
-------------------

# 安装
首先，从github上下载源代码：[BVLC/caffe](https://github.com/BVLC/caffe)。按照[install instruction](http://caffe.berkeleyvision.org/installation.html)的指导进行安装。分别有2个版本的安装，我目前只安装了CPU版本。之后会继续安装GPU版本。
CPU版本安装过程：

 - cp Makefile.config.example Makefile.config
 - Adjust Makefile.config (for example, if using Anaconda Python, or if cuDNN is desired)
 - make all
 - make test
 - make runtest
其中，我设置的Makefile.config的内容为（使用的blas库是mkl的）：
![这里写图片描述](http://img.blog.csdn.net/20170227184626156?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDQ1ODg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

# 运行例子：mnist（手写体识别）
## 1.使用手写体识别应用训练LeNet模型
参考如下的步骤，进行操作：[example-mnist](http://caffe.berkeleyvision.org/gathered/examples/mnist.html)。
    

 1. 下载数据集，并进行格式转换：（都是在caffe的root目录下进行的）
    
         1. ./data/mnist/get_mnist.sh
         2. ./examples/mnist/create_mnist.sh
    
 2.  定义网络
     具体参考：
    $CAFFE_ROOT/examples/mnist/lenet_train_test.prototxt

 3. 定义求解器
     具体参考：
    $CAFFE_ROOT/examples/mnist/lenet_solver.prototxt

 4. 开始训练和测试
    cd $CAFFE_ROOT
    ./examples/mnist/train_lenet.sh
    运行完后，结果存储在：./examples/mnist/lenet_iter_10000文件中（注意，10000代表迭代次数）。
    

## 2.相关名词解释
1.batch_size、epoch and iteration
（1）batchsize：批大小。在深度学习中，一般采用SGD训练，即每次训练在训练集中取batchsize个样本训练；
（2）iteration：1个iteration等于使用batchsize个样本训练一次；
（3）epoch：1个epoch等于使用训练集中的全部样本训练一次；
举个例子，训练集有1000个样本，batchsize=10，那么：
训练完整个样本集需要：100次iteration，1次epoch。
2.求解器里的参数含义
![mnist-solver](http://img.blog.csdn.net/20170227191045424?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDQ1ODg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
base_lr：基准学习率。另外每个layer会在基准上微调。（负梯度的权重）
momentum：遗忘因子。历史权值所占的权重。
weight_decay:权值衰减常数。
lr_policy:step/inv。学习率衰减方式。step为步进方式。没进行step步，学习率更新一次。inv为倒数衰减。还有sigmoid，multistep（类似步进），poly（多项式），exp（指数），fixed（固定的学习率）。
gamma:学习率衰减常数。每次更新学习率时，乘上此常数。
power: TODO？

## reference
【1】[batch size](https://zhidao.baidu.com/question/201951328759691645.html)
【2】[mnist-example](http://caffe.berkeleyvision.org/gathered/examples/mnist.html)
【3】深度学习21天实战Caffe 赵永科著
