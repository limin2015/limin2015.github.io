---
layout:     post
title:      CUDA编程实践-1
keywords:   安装、基本接口、小例子
category:   CUDA
tags:		[CUDA编程]
---


# 基础知识

（1）函数的类型。

\__host__ float HostFunc():默认情况。被host函数调用，在host函数上执行。（host指cpu端）

\__devide__ float DeviceFunc(); 被设备函数调用，在设备上执行。（设备指gpu）

\__global__ void KernelFunc(): 被host函数调用，在设备上执行。

注意:


	（a）\__global__ 函数返回值必须为void
	（b）设备上执行的函数：不能是递归的，函数参数必须固定，不能再函数内部使用static变量。

（2）变量类型


![这里写图片描述](http://img.blog.csdn.net/20170302200509623?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDQ1ODg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20170302200550980?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDQ1ODg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


\__shared__ A[4]；//在share memory，块内线程共享。

设备上的函数，声明的变量都是存在register上的，存不下的放到local memory；

cudaMalloc()的空间是在设备的global memory上的。

(3)几个cuda头文件

        #include<cuda_runtime.h>:  里面包含cuda 的基本routine
        #include <helper_cuda.h>：里面包含error处理等routine
        #include <helper_functions.h>： 这里面是什么？？？



##关于计算地址：

个人感觉这里是最迷糊人的。需要好好想清楚。

思路：先求块首地址，再加块内地址。

1. grid是一维，block是一维，如何计算线程号：
![](http://img.blog.csdn.net/20170301134426181?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDQ1ODg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
注意：这个好理解。blockDim相当于一个块内的线程总数。blockIdx.x相当于当前线程是第几块。threadIdx.x相当于当前线程时第几个线程（块内）。（有空时画个图便于理解）

2. Grid是2维，block是3维：
    
    dim3 dimGrid(2, 2);
    dim3 dimBlock(2, 2, 2);

全局块号：blockIdx.y*gridDim.x+blockIdx.x

全局块内线程号：threadIdx.z * blockDim.x * blockDim.y + threadIdx.y * blockDim.x + threadIdx.x

**注意**：2维的可以以列优先存储的矩阵方式来理解。3维的时候，可以理解成多层的矩阵。


## 各种延迟整理（TODO）

    Instruction latencies: – Roughly 10-20 cycles (replays increase these) 
    DRAM accesses have higher latencies (400-800 cycles)




