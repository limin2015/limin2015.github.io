---
layout:     post
title:      paper-The Tensor Algebra Compiler(taco)
keywords:   paper-taco2017
category:   [paper]
tags:       [paper]
---

这篇paper，主要讲了如何自动化生产代码。里面的算法非常的好，需要多读几遍，多多体会。（好的work，算法往往不是很难，却能产生好的效果，让人眼前一亮。）

**思考**：如何把它用到gpu代码的自动生产呢？？



# 出处：
2017年，OOPSLA（ccf-a）

# 要解决的问题：



# motivation：

1.实际应用中使用了很多 张量代数运算，而且大部分都是sparse的；这些张量表达式的计算是非常复杂的：稀疏的输入tensor应用进行压缩存储；输出只需要产生非零元即可；如何迭代计算，使得访问更加连续；
2.目前已有的方法是手写高性能的kernel。一方面，库里面提供了一些常用的kernel，对于复杂的kernel，可以通过调用多个库里面的kernel来实现，但这降低了locality和efficiency；另一方面，复杂的Tensor表达式有很多，手工是无法穷举的。
因此，使用编译的方法为tensor表达式自动生成高性能的kernel是很有必要的 ；


# 主要内容：


present the first compiler technique that can generate kernels for all sparse and dense tensor index notation expressions(dense and sparse linear algebra expressions):

tensor storage formats that separately designate each dimension as dense or sparse and specify the order in which dimensions are stored, which can describe several widely used formats but generalizes to many more (Section 3);
iteration graphs that describe how to co-iterate through the multi-level index data structures of the sparse operands in a compound tensor expression (Section 4);
merge lattices that describe how to merge the index data structures of sparse tensors that are used in the same tensor expression (Section 5); and a
code generation algorithm that uses the above concepts to generate efficient code that computes a tensor expression with dense, sparse, and mixed operands (Section 6).


## Tensor Storage:

## Iteration graph:

## Merge lattice:

## Code generation:

## Parallel Code Generation（并行代码生成部分）

1.只支持在最外层for循环外，加一个openmp的并行； without yet implementing sophisticated optimizations for parallelism and vectorization。
（1）
（2）不支持同步的代码生成；
（3）输出的tensor各个维度都是dense的；


# 实验结果：

on a two-socket, 12-core/24-thread 2.4 GHz Intel Xeon E5-2695 v2 machine with 32 KB of L1 data cache, 30 MB of L3 cache per socket, and 128 GB of main memory, running MATLAB 2016b and GCC 5.4.





# 前人工作

Tf支持稀疏的tensor操作：
https://www.tensorflow.org/api_guides/python/sparse_ops



# 可以改进的地方：

taco currently does not support NUMA-aware code generation.
1.本文只支持share-memory上的代码生成（omp），未来可以拓展到gpu，TPU，分布式内存系统等平台上。
2.格式上：目前每一维度只支持dense和sparse两种格式，未来还可以试试： coordinate format， diagonal formats, hashed formats
3.自动调优：本文只提供了很多种格式，但是how to autotune choice of formats and expression granularity值得探索. This includes search, model-driven optimization, machine learning, and heuristics。
4.



# 主要内容：


Some blogs：
http://www.sohu.com/a/203176510_297710

http://www.sohu.com/a/201980382_114877
