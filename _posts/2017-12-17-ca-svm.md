---
layout:     post
title:      paper-CA-SVM
keywords:   distributed svm algo(CA-SVM)
category:   [paper]
tags:       [paper]
---

这篇文章是yangyou发表在2015年IPDPS上的论文。写得非常好，获得了IPDPS的best paper. 文中提到的几个分布式的svm算法，
如何想出来的，思路非常的好，值得学习。有一种很简单，却又很valuable的感觉（pursue）。

论文地址：
[CA-SVM Communication-Avoiding Support Vector Machines on Distributed Systems](https://people.eecs.berkeley.edu/~youyang/publications/ipdps2015.pdf)


# 一、摘要

**解决的问题**：how to design and implement communication-efficient versions of parallel svm for distributed memory clusters and supercomputers.

**已有的**：the parallel isoefficiency of a state-of-the-art
implementation scaled as W = Ω(P3), where W is the problem
size and P the number of processors;

**我们做的**：considers a series of algorithmic refinements,
leading ultimately to a Communication-Avoiding SVM (CASVM)
method that improves the isoefficiency to nearly W =
Ω(P).

**结果**：

- on 96 to 1536 processors with average speedups of 3 − 16× (7× on average)
over Dis-SMO;

- a 95% weak-scaling efficiency on six realworld
datasets, with only modest losses in overall classification
accuracy.


# 二、introduction

先解释了为什么现在的分布式svm是W = Ω(P3)；

先分析已有的三个分布式svm算法：SMO [9], Cascade SVM [10], and Divide-and-Conquer
SVM (DC-SVM) [11].然后给出我们的改进和优化：
- (1) developing a
Divide-and-Conquer Filter (DC-Filter) method, which combines
Cascade SVM with DC-SVM to balance accuracy
and performance; 
- (2) designing a Clustering-Partition SVM
(CP-SVM) to improve the parallelism, reduce the communication,
and improve accuracy relative to DC-Filter; and
- (3) designing a novel Communication-Avoiding SVM (CASVM)
that achieves load-balance and removes nearly all
inter-node communication.

**本文focus on**： 

we focus on a class of algorithms
we will call **partitioned** SMO algorithms. These algorithms
work essentially by partitioning the data set, building kernel
SVM models for each partition using SMO as a building
block, and then combining the models to derive a single
final model.


**一个发现**： the number of
iterations necessary for convergence will tend to scale with
the number of input points, m. （\red{为什么呢？他是采取做实验方式，让别人信服的}）




# 三、已有的分布式svm算法

** cao[12]'s algo**：
还没看这个文献！！


**cascade-svm**：

**思路**：

- divide the SVM problem into P smaller
SVM sub-problems, and then use a kind of “reduction tree”
to re-combine these smaller SVM models into a single result.

- A Cascade SVM system with
P computing nodes has log(P)+1 layers.

- 上层只往下层传递SVs，上面2层的SVs构成了下面一层的训练数据集。（注意sv其实就是训练数据集的子集）。

\\
![](/images/paper/ca-svm-cascade-1.png)\\
![](/images/paper/ca-svm-cascade-2.png)




**DC-svm**：

**思路**：

在cascade-svm的基础上，有2点不同：

- (1）Cascade SVM partitions the training dataset evenly on the first layer, 
while DC-SVM uses **Kmeans clustering** to partition the dataset; 

- (2) Cascade SVM only passes the set of support vectors from one layer
to the next, whereas DC-SVM passes all of the training
dataset from layer to layer. At the last layer of DC-SVM, a
single SVM operates on the whole training dataset. 
（我的疑问：最后一层相当于一个节点对所有数据集进行svm训练，数据能放得下吗？如果可以放得下，为什么要用这种分布式的算法呢？---》因为前面一些层的处理，相当于进行了一些迭代，跟单节点跑一次svm相比，最后跑的快一些。）





# 四、本文提出的分布式svm算法

进行了几次尝试：分别如下。

## DC-Filter: combination of cascade-svm and DC-svm

通过简单实验发现：
Cascade is faster than Dis-SMO. However, the classification accuracy
of Cascade is worse. DC-SVM can obtain a higher
classification accuracy. Nevertheless, the algorithm becomes
extremely slow。

将已有的两个方法攒在了一起：使用DC-svm的kmeans进行分割，使用cascade的filter方法，上一层只传递支持向量到下一层，而不传递data set。

结果表明, the speed and accuracy of DC- Filter fall
in between Cascade and DC-SVM, or perform better than
both of them.


## CP-svm:基于聚类分割的svm算法


**以上提及的方法的不足**：

cascade-svm，DC-svm，DC-Filter都是基于分层的结构，只有在第一层的时候，所有的节点都在使用，越往下，node减半，导致node的利用率不高。（作者对这里的说明，不是简单的说一下，而是用实验来表明，学习一下！！）



**思路**：
使用kmeans将数据集分成p个集合，然后每个node使用对每一个集合的数据集进行svm训练过程，每个node都得到一个训练模型，共得到p个训练模型。预测的时候，看看要测试的样本，离哪个集合更近一些，就用那个node产生的训练模型进行预测。（本质上就是只取了DC-svm的第一层。）

**原理解释**：\\

![](/images/paper/ca-svm-cp-algo.png)


**CP-svm存在的不足**：

有负载不均衡的问题。因为kmeans聚类产生的结果，每个簇中的样本的数目可能相差很大。
接下来的算法，就是为了解决这个问题。
也就是：如何分割（什么样的聚类算法），能够产生负载均衡的分割结果？
其实本质上就是设计一个负载均衡的聚类算法！！



## CA-svm:

为了解决CP-svm存在的不足，改进了以下几种方案：

**FCFS CASVM**：

相当于：对kmeans聚类稍微改进一下，加了一个条件，为每个样本点找其中心点的时候，
不是找最近的，而是找没有满的簇中的最近的中心点。

**balanced kmeans CASVM**：

先进行kmeans聚类，然后再把样本数多于平均的移到样本数少于平均的簇（keep moving samples from the over-loaded center to an under-loaded center till they are balanced）。
具体的移动策略：

- 先将所有样本点和所有中心点之间的距离矩阵计算出来。（注：这部分开销其实挺大的！！）

- For a given over-loaded center, we will find the farthest sample. 
The id of the farthest sample is maxind. 
Then, we find the closest
under-loaded center to sample maxind. 
At last, we move sample maxind from its over-loaded center to the
best under-loaded center.



**random-averaging CASVM**：
随机平均分方法：随机的将样本数据均匀的分成p份。
（这种方法其实就是取了cascade-svm的第一层）
（我感觉这种方法会对正确性产生影响，可是结果显示没有啥影响。为什么呢？）



# 五、实验设计及结果

TODO


# 六、学到的知识


one-dimensional block row dense matrix vector
multiplication, which has W = Ω(P2): 这个我不知道如何算？

iso-efficiency：

对已有算法建模的部分： 再读几遍！！没有领会！
