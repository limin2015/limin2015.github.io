---
layout: post
title:  CUDA性能优化-存储体冲突
keywords: CUDA
categories : [CUDA]
tags : [CUDA编程]
---

介绍cuda性能优化的几个重要的点。及其比较新的一些feature。（一个月的时间内，整理完成！！）


# 存储体冲突是什么？

bank-conflict:


#如何减少存储体冲突？



## 什么时候使用cudaThreadSynchronize()？

等待kernel执行完毕。
cpu端发起kernel<<< >>>之后（异步的），就可以继续执行下面的程序（该程序段与gpu加速的没有依赖关系）。使用
cudaThreadSynchronize()后，cpu会等待gpu的结果返回后，才继续执行下面的指令。

## global-mem的合并访问：不大很明白

是说：相邻线程访问相邻的元素吗？
比如任务分配的时候，采用的方式是0号第0个元素，1号第1个元素，然后round-robin方式继续进行下去。

## block间共享数据的时候，必须通过global-mem吗？

是的！


## cuda分块时的线程索引，位置确定。我有点晕了的！！


今天必须解决：OK，二维的，画图示意，写坐标。



## cuda中使用 #pragma unroll 是做什么的？？

显示的做循环展开。

## 寄存器变量的使用：

http://blog.csdn.net/tiemaxiaosu/article/details/52932455

http://blog.csdn.net/tiemaxiaosu/article/details/52956150

http://blog.csdn.net/tiemaxiaosu/article/details/52932455

http://blog.csdn.net/u013507368/article/details/43370423

http://blog.csdn.net/Bruce_0712/article/details/65664840


## 寄存器使用过多成为CUDA程序瓶颈的情况分析：（还没看）

http://blog.csdn.net/u013443737/article/details/23422569


## GTC2017：（去看看！！）

http://www.gputechconf.com/gtcnew/on-demand-gtc.php



## 一篇博客，写如何改善gpu性能的，很有用

https://www.cnblogs.com/Jnshushi99/p/4711060.html

https://www.cnblogs.com/ghl_carmack/p/4107042.html



## too much shared memory allocated to one block limits the number of active blocks per multiprocessor:

若一个块内分配的shmem太多，则活跃的块数就会受限制。（有什么具体的关系吗？）



## 关于bank conflict的解释：

![](/images/cuda/bank-conflict.png)

一个块内的线程，最好相邻线程访问的是相邻的内存。否则容易bank conflict。


下面的介绍很好：（good！！）

http://blog.csdn.net/u013701860/article/details/50253343



## texture-memory：

只读的；（必须全局声明！！）

http://john-waindinger.blog.163.com/blog/static/232830112201472694143498/

这个介绍不错：


http://blog.csdn.net/zhangfuliang123/article/details/76528075


## stream相关：（TODO）

http://blog.csdn.net/zdy0_2004/article/details/52602499


## 关于汇编（ptx等）相关的：

asfermi：我把它下载并放到了124服务器上，编译通过了的。

https://code.google.com/archive/p/asfermi

它的使用等：

https://code.google.com/archive/p/asfermi/wikis/CodeExample.wiki



## float2和float4向量数据类型是什么鬼？？




## CULA是什么库？开源吗？

基于CUDA的一个lapack库。


## launch bounds  及  if (__CUDA_ARCH__ >= 200)这句是什么意思：


## PTX代码的学习：

官方文档：

http://docs.nvidia.com/cuda/parallel-thread-execution/index.html#axzz3x1T0rHkf

别人的博客：

http://blog.csdn.net/fishseeker/article/details/75214167
http://blog.csdn.net/litdaguang/article/details/50505885
http://blog.csdn.net/litdaguang/article/details/50505885
http://blog.csdn.net/Canhui_WANG/article/details/52892676


SASS指令集。NVASM和cuobjdump上有一些，但感觉不全。NV没有公布过assembler。Fermi上可以去看开源的asfermi，里面讲了一些。Maxwell可以去查maxas，其他的应该没了。








